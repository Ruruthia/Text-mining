{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def preprocess(word):\n",
    "\n",
    "    new_word = \"\"\n",
    "    final_word = \"\"\n",
    "\n",
    "    s1 = {\"ó\": \"o\",\n",
    "     \"ę\": \"e\",\n",
    "     \"ą\": \"a\",\n",
    "     \"ć\": \"c\",\n",
    "     \"ź\": \"z\",\n",
    "     \"ż\": \"z\"}\n",
    "\n",
    "    s2 = {\"rz\": \"ż\",\n",
    "     \"ch\": \"h\"}\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        if (i+1 < len(word)) and (word[i] + word[i+1] in s2):\n",
    "            new_word += s2[word[i] + word[i+1]]\n",
    "        else:\n",
    "            new_word += word[i]\n",
    "\n",
    "    for i in range(len(new_word)):\n",
    "        if new_word[i] in s1:\n",
    "            final_word += s1[new_word[i]]\n",
    "        else:\n",
    "            final_word += new_word[i]\n",
    "\n",
    "    final_word = ''.join(c[0] for c in itertools.groupby(final_word))\n",
    "    return final_word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "WORDS = set(pd.read_csv('../List_3/data/words.txt', sep=\";\", header=None)[0])\n",
    "WORDS_EXT = set(pd.read_csv('../List_3/data/words.txt', sep=\";\", header=None)[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "N_GRAMS = {word: set(map(\"\".join, ngrams(preprocess(word), 2))) for word in WORDS}\n",
    "N_GRAMS_EXT = {word: set(map(\"\".join, ngrams(preprocess(word), 2))) for word in WORDS_EXT}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ERRORS = pd.read_csv('../List_3/data/literowki1.txt', sep=\" \", header=None, names=['correct', 'error'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def correct_error(word):\n",
    "    if word in WORDS:\n",
    "        return [word]\n",
    "    else:\n",
    "        processed_word = preprocess(word)\n",
    "        possible_words = {}\n",
    "        word_ngrams = set(map(\"\".join, ngrams(processed_word, 2)))\n",
    "        for correct_word, correct_ngrams in N_GRAMS.items():\n",
    "            if len(word_ngrams & correct_ngrams) > 0.40 * len(word_ngrams):\n",
    "                possible_words[correct_word] = preprocess(correct_word)\n",
    "        if len(possible_words) < 500:\n",
    "            for correct_word, correct_ngrams in N_GRAMS_EXT.items():\n",
    "                if len(word_ngrams & correct_ngrams) > 0.40 * len(word_ngrams):\n",
    "                    possible_words[correct_word] = preprocess(correct_word)\n",
    "        min_editdist = 100\n",
    "        best_word = []\n",
    "        for correct_word, processed_correct_word in possible_words.items():\n",
    "            editdist = edit_distance(processed_correct_word, processed_word, transpositions=True)\n",
    "            if editdist == min_editdist:\n",
    "                best_word.append(correct_word)\n",
    "            if editdist < min_editdist:\n",
    "                min_editdist = editdist\n",
    "                best_word = [correct_word]\n",
    "        if min_editdist > 3:\n",
    "            \n",
    "        return best_word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def find_from_best(w, best):\n",
    "    scores = {}\n",
    "    w = preprocess(w)\n",
    "    for b in best:\n",
    "        cb = b\n",
    "        b = preprocess(b)\n",
    "        i = 0\n",
    "        scores[cb] = 0\n",
    "        tries = 1\n",
    "        while b[i] == w[i] or tries:\n",
    "            if b[i] != w[i]:\n",
    "                tries = 0\n",
    "            scores[cb] += 1 + tries\n",
    "            i += 1\n",
    "            if i == min(len(b), len(w)) or i > 3:\n",
    "                break\n",
    "        i = -1\n",
    "        tries = 1\n",
    "        while b[i] == w[i] or tries:\n",
    "            if b[i] != w[i]:\n",
    "                tries = 0\n",
    "            scores[cb] += 1 + tries\n",
    "            i -= 1\n",
    "            if i == - min(len(b), len(w)) - 1 or i < -3:\n",
    "                break\n",
    "        scores[cb] -= 2 * abs(len(b) - len(w))\n",
    "    s = sorted(scores, key=scores.get, reverse=True)\n",
    "    return s[0], s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faeb0f45829441ad89d3af2d254e64f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "pospuszczać podpuszczać posdupszcać\n",
      "['pospuszczać', 'poduszczać']\n",
      "0.6666666666666666\n",
      "poduszczać podpuszczać podpszżczać\n",
      "['poduszczać', 'podpuszczać']\n",
      "0.5\n",
      "0.6\n",
      "0.6666666666666666\n",
      "0.7142857142857143\n",
      "0.75\n",
      "0.7777777777777778\n",
      "0.8\n",
      "wydatkowego wyjątkowego wyatkowrego\n",
      "['wydatkowego', 'wyjątkowego', 'wątkowego']\n",
      "0.7272727272727273\n",
      "0.75\n",
      "0.7692307692307693\n",
      "0.7857142857142857\n",
      "0.8\n",
      "0.8125\n",
      "0.8235294117647058\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "r = 1\n",
    "for i, (correct, error) in tqdm(ERRORS[::-1].iterrows()):\n",
    "    best = correct_error(error)\n",
    "    corrected, scores = find_from_best(error, best)\n",
    "    if corrected == correct:\n",
    "        acc += 1\n",
    "    else:\n",
    "        print(corrected, correct, error)\n",
    "        print(scores)\n",
    "    print(acc / r)\n",
    "    r+=1\n",
    "print(100 * acc/len(ERRORS))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}